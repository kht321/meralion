{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928718db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install torch transformers librosa accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f237b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear GPU cache before importing large libraries\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e816e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19846d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading processor...\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270d6fcaa63442e1bc532d574ee74e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"MERaLiON/MERaLiON-2-3B\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#  clear GPU cache before loading model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Loading processor...\")\n",
    "processor = AutoProcessor.from_pretrained(repo_id, trust_remote_code=True)\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    repo_id,\n",
    "    use_safetensors=True,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"eager\",   # <--- force eager attention\n",
    "    torch_dtype=torch.bfloat16 if device==\"cuda\" else torch.float32,\n",
    ").to(device)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5716baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"Instruction: Please transcribe this speech. \\n\"\n",
    "    \"Follow the text instruction based on the following audio: <SpeechHere>\"\n",
    ")\n",
    "conversation = [[{\"role\": \"user\", \"content\": prompt_template}]]\n",
    "chat_prompt = processor.tokenizer.apply_chat_template(\n",
    "    conversation=conversation, tokenize=False, add_generation_prompt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57510f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(audio_path, queries=None):\n",
    "    \"\"\"\n",
    "    Process audio file with given queries (memory-efficient version)\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to your audio file\n",
    "        queries: List of query strings (defaults to transcribe and translate)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "    \n",
    "    print(f\"Loading audio: {audio_path}\")\n",
    "    \n",
    "    # Load audio at 16kHz\n",
    "    audio_array, sample_rate = librosa.load(audio_path, sr=16000)\n",
    "    print(f\"Audio loaded: {len(audio_array)/sample_rate:.2f} seconds\")\n",
    "\n",
    "    # only process first 30 seconds\n",
    "    audio_array = audio_array[:30 * sample_rate]\n",
    "    print(f\"Processing first {len(audio_array)/sample_rate:.2f} seconds of audio\")\n",
    "    \n",
    "    inputs = processor(text=chat_prompt, audios=[audio_array])\n",
    "    for k, v in list(inputs.items()):\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            v = v.to(device)\n",
    "            if device==\"cuda\" and v.dtype==torch.float32:\n",
    "                v = v.to(torch.bfloat16)\n",
    "            inputs[k] = v\n",
    "\n",
    "    # --- Generate transcription ---\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "\n",
    "    generated_ids = outputs[:, inputs[\"input_ids\"].size(1):]\n",
    "    transcript = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # clear GPU cache after processing\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"--------------------------------------------\")\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ebcd2",
   "metadata": {},
   "source": [
    "# Getting transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b060661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/fairness/audio\\test1.mp3\n",
      "Loading audio: data/fairness/audio\\test1.mp3\n",
      "Audio loaded: 96.67 seconds\n",
      "Processing first 30.00 seconds of audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65900\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:182: RuntimeWarning: Mean of empty slice.\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "C:\\Users\\65900\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\65900\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:182: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
      "C:\\Users\\65900\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\65900\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test10.mp3\n",
      "Loading audio: data/fairness/audio\\test10.mp3\n",
      "Audio loaded: 102.47 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test2.mp3\n",
      "Loading audio: data/fairness/audio\\test2.mp3\n",
      "Audio loaded: 103.86 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test21.mp3\n",
      "Loading audio: data/fairness/audio\\test21.mp3\n",
      "Audio loaded: 53.01 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test22.mp3\n",
      "Loading audio: data/fairness/audio\\test22.mp3\n",
      "Audio loaded: 22.99 seconds\n",
      "Processing first 22.99 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test23.mp3\n",
      "Loading audio: data/fairness/audio\\test23.mp3\n",
      "Audio loaded: 37.72 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test24.mp3\n",
      "Loading audio: data/fairness/audio\\test24.mp3\n",
      "Audio loaded: 88.98 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test25.mp3\n",
      "Loading audio: data/fairness/audio\\test25.mp3\n",
      "Audio loaded: 52.64 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test26.mp3\n",
      "Loading audio: data/fairness/audio\\test26.mp3\n",
      "Audio loaded: 1716.58 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test27.mp3\n",
      "Loading audio: data/fairness/audio\\test27.mp3\n",
      "Audio loaded: 2399.97 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test28.mp3\n",
      "Loading audio: data/fairness/audio\\test28.mp3\n",
      "Audio loaded: 1561.24 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test29.mp3\n",
      "Loading audio: data/fairness/audio\\test29.mp3\n",
      "Audio loaded: 21.71 seconds\n",
      "Processing first 21.71 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test3.mp3\n",
      "Loading audio: data/fairness/audio\\test3.mp3\n",
      "Audio loaded: 100.66 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test30.mp3\n",
      "Loading audio: data/fairness/audio\\test30.mp3\n",
      "Audio loaded: 28.71 seconds\n",
      "Processing first 28.71 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test4.mp3\n",
      "Loading audio: data/fairness/audio\\test4.mp3\n",
      "Audio loaded: 28.54 seconds\n",
      "Processing first 28.54 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test5.mp3\n",
      "Loading audio: data/fairness/audio\\test5.mp3\n",
      "Audio loaded: 43.49 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test6.mp3\n",
      "Loading audio: data/fairness/audio\\test6.mp3\n",
      "Audio loaded: 87.01 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test7.mp3\n",
      "Loading audio: data/fairness/audio\\test7.mp3\n",
      "Audio loaded: 54.92 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test8.mp3\n",
      "Loading audio: data/fairness/audio\\test8.mp3\n",
      "Audio loaded: 42.10 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Processing file: data/fairness/audio\\test9.mp3\n",
      "Loading audio: data/fairness/audio\\test9.mp3\n",
      "Audio loaded: 88.17 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n",
      "Transcription results saved to results/fairness/transcription_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE_PATH = \"data/fairness/audio\" # path to fairness audio files\n",
    "\n",
    "try:\n",
    "    # Process the audio files\n",
    "    results = []\n",
    "    audios = []\n",
    "    for audio_file in os.listdir(AUDIO_FILE_PATH):\n",
    "        if audio_file.endswith(\".wav\") or audio_file.endswith(\".mp3\"):\n",
    "            full_path = os.path.join(AUDIO_FILE_PATH, audio_file)\n",
    "            audios.append(audio_file)\n",
    "            print(f\"Processing file: {full_path}\")\n",
    "    \n",
    "            results.append(process_audio_file(full_path))\n",
    "            \n",
    "    # save results in an excel file with columns filename, transcript\n",
    "    df = pd.DataFrame({\"Filename\": audios, \"Transcription\": results})\n",
    "    df.to_excel(\"results/fairness/transcription_results.xlsx\", index=False)\n",
    "\n",
    "    print(\"Transcription results saved to results/fairness/transcription_results.xlsx\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio: audio/test28.mp3\n",
      "Audio loaded: 1561.24 seconds\n",
      "Processing first 30.00 seconds of audio\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<Speaker1>: Singapore president Halimah Yacob is just about to address the country's parliament as it reopens after a recess of a little more than two weeks. The recess, which happens when parliament is prorogued, typically marks the midpoint of the government's current term. Madam Halimah is expected to outline the government's priorities, policies and programs ahead of the remainder of its term. Her speech comes as the nation rebounds from the impact of Covid Nineteen, but with the spectre of geopolitical tensions.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_audio_file(f'{AUDIO_FILE_PATH}/test28.mp3') # for specific file testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbda2d",
   "metadata": {},
   "source": [
    "# Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "877a0fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: It's my final day here in Switzerl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test10.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I'm in Paris and I want to do some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I did it. I got the iPhone Air. Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test21.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: Brian, look at me. This is not you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test22.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I designed this yoga bag and it wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                      Transcription\n",
       "0   test1.mp3  <Speaker1>: It's my final day here in Switzerl...\n",
       "1  test10.mp3  <Speaker1>: I'm in Paris and I want to do some...\n",
       "2   test2.mp3  <Speaker1>: I did it. I got the iPhone Air. Lo...\n",
       "3  test21.mp3  <Speaker1>: Brian, look at me. This is not you...\n",
       "4  test22.mp3  <Speaker1>: I designed this yoga bag and it wa..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the transcription results\n",
    "df = pd.read_excel(\"results/fairness/transcription_results.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af7addf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(\"results/fairness/metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab1e9e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>meralion</th>\n",
       "      <th>Added by</th>\n",
       "      <th>Video</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Age</th>\n",
       "      <th>GT</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: It's my final day here in Switzerl...</td>\n",
       "      <td>yy</td>\n",
       "      <td>https://www.instagram.com/reel/DO7kMR-Exnm/?ut...</td>\n",
       "      <td>F</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>31</td>\n",
       "      <td>&lt;Speaker1&gt;: It's my final day here in Switzerl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test10.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I'm in Paris and I want to do some...</td>\n",
       "      <td>yy</td>\n",
       "      <td>https://www.tiktok.com/@zakiv4/video/754969856...</td>\n",
       "      <td>M</td>\n",
       "      <td>Malay</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;Speaker1&gt;: I'm in Paris and I want to do some...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I did it. I got the iPhone Air. Lo...</td>\n",
       "      <td>yy</td>\n",
       "      <td>https://www.tiktok.com/@thejianhaotan/video/75...</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Speaker1&gt;: I did it. I got the iPhone Air. Lo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test21.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: Brian, look at me. This is not you...</td>\n",
       "      <td>yun si</td>\n",
       "      <td>https://www.tiktok.com/@syapls/video/752244596...</td>\n",
       "      <td>F</td>\n",
       "      <td>Malay</td>\n",
       "      <td>28</td>\n",
       "      <td>&lt;Speaker1&gt;: Brian, look at me. This is not you...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test22.mp3</td>\n",
       "      <td>&lt;Speaker1&gt;: I designed this yoga bag and it wa...</td>\n",
       "      <td>yun si</td>\n",
       "      <td>https://www.instagram.com/p/DA8ZO6Wy-Kx/</td>\n",
       "      <td>F</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>34</td>\n",
       "      <td>&lt;Speaker1&gt;: I designed this yoga bag and it wa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                           meralion Added by  \\\n",
       "0   test1.mp3  <Speaker1>: It's my final day here in Switzerl...       yy   \n",
       "1  test10.mp3  <Speaker1>: I'm in Paris and I want to do some...       yy   \n",
       "2   test2.mp3  <Speaker1>: I did it. I got the iPhone Air. Lo...       yy   \n",
       "3  test21.mp3  <Speaker1>: Brian, look at me. This is not you...   yun si   \n",
       "4  test22.mp3  <Speaker1>: I designed this yoga bag and it wa...   yun si   \n",
       "\n",
       "                                               Video Gender     Race Age  \\\n",
       "0  https://www.instagram.com/reel/DO7kMR-Exnm/?ut...      F  Chinese  31   \n",
       "1  https://www.tiktok.com/@zakiv4/video/754969856...      M    Malay  30   \n",
       "2  https://www.tiktok.com/@thejianhaotan/video/75...      M  Chinese  32   \n",
       "3  https://www.tiktok.com/@syapls/video/752244596...      F    Malay  28   \n",
       "4           https://www.instagram.com/p/DA8ZO6Wy-Kx/      F  Chinese  34   \n",
       "\n",
       "                                                  GT  Accuracy  \n",
       "0  <Speaker1>: It's my final day here in Switzerl...       NaN  \n",
       "1  <Speaker1>: I'm in Paris and I want to do some...       NaN  \n",
       "2  <Speaker1>: I did it. I got the iPhone Air. Lo...       NaN  \n",
       "3  <Speaker1>: Brian, look at me. This is not you...       NaN  \n",
       "4  <Speaker1>: I designed this yoga bag and it wa...       NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc WER & CER base on GT & meralion output\n",
    "!pip install jiwer\n",
    "\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "from jiwer import wer, cer\n",
    "\n",
    "def compute_metrics(reference: str, hypothesis: str) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"wer\": wer(reference, hypothesis),\n",
    "        \"cer\": cer(reference, hypothesis),\n",
    "    }\n",
    "metrics = []\n",
    "for index, row in df.iterrows():\n",
    "    filename = row[\"Filename\"]\n",
    "    hypothesis = row[\"Transcription\"]\n",
    "    reference_row = metadata[metadata[\"Filename\"] == filename]\n",
    "    if not reference_row.empty:\n",
    "        reference = reference_row.iloc[0][\"GT\"]\n",
    "        metrics.append(compute_metrics(reference, hypothesis))\n",
    "    else:\n",
    "        print(f\"Warning: No reference found for {filename}\")\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df[\"Filename\"] = df[\"Filename\"]\n",
    "metrics_df[\"WER\"] = metrics_df[\"wer\"]\n",
    "metrics_df[\"CER\"] = metrics_df[\"cer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
