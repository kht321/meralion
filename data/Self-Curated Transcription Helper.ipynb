{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMGHuL+GxMG0eJPDoOJfXLz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"649af95b88684bedb73cca399cb8ceb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ac7a0e16d4e46eaa3e60229421d0181","IPY_MODEL_f51d402e8fbd4d89be28285018935217","IPY_MODEL_faf15ce314a84e2d8f2a77cea760df9e"],"layout":"IPY_MODEL_541a26429fbf41a79a2c89cc5703a1ae"}},"5ac7a0e16d4e46eaa3e60229421d0181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00180f19f17b434fbb1b8050eaab9ec0","placeholder":"​","style":"IPY_MODEL_db894934c9dd4f8bb97e1d12dd3150f5","value":"Loading checkpoint shards: 100%"}},"f51d402e8fbd4d89be28285018935217":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09064e989b4240f89958fae39ad31973","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6320e2bb8ed44685a4ac233e720b0a69","value":2}},"faf15ce314a84e2d8f2a77cea760df9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be41bd5c5c3c457bba2a608a97e2e8ca","placeholder":"​","style":"IPY_MODEL_21151a3cf19d4a88a898818cbafa64b0","value":" 2/2 [00:09&lt;00:00,  5.21s/it]"}},"541a26429fbf41a79a2c89cc5703a1ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00180f19f17b434fbb1b8050eaab9ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db894934c9dd4f8bb97e1d12dd3150f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09064e989b4240f89958fae39ad31973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6320e2bb8ed44685a4ac233e720b0a69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be41bd5c5c3c457bba2a608a97e2e8ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21151a3cf19d4a88a898818cbafa64b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# --- Install ---\n","!pip install \"transformers==4.50.1\" librosa\n","# (optional, GPU speedup)\n","!pip install flash-attn --no-build-isolation\n","\n","# --- Imports ---\n","import torch, librosa\n","from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0JfxstFBxP1","executionInfo":{"status":"ok","timestamp":1759512803265,"user_tz":-480,"elapsed":43159,"user":{"displayName":"Zexel Nicholas LEW _","userId":"04644860967599150993"}},"outputId":"6a6d9819-f3da-40da-d8de-392c1ccf4974","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.50.1 in /usr/local/lib/python3.12/dist-packages (4.50.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (2.32.4)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.50.1) (4.67.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.2)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n","Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.1) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.1) (1.1.10)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.4.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.50.1) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.50.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.50.1) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.50.1) (2025.8.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n","Collecting flash-attn\n","  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.8.0+cu126)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.3)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=256040057 sha256=f25da18657a87fc83dc1bfb8b7751b82246e9db355510226b674fd437c34b5fb\n","  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-2.8.3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["649af95b88684bedb73cca399cb8ceb9","5ac7a0e16d4e46eaa3e60229421d0181","f51d402e8fbd4d89be28285018935217","faf15ce314a84e2d8f2a77cea760df9e","541a26429fbf41a79a2c89cc5703a1ae","00180f19f17b434fbb1b8050eaab9ec0","db894934c9dd4f8bb97e1d12dd3150f5","09064e989b4240f89958fae39ad31973","6320e2bb8ed44685a4ac233e720b0a69","be41bd5c5c3c457bba2a608a97e2e8ca","21151a3cf19d4a88a898818cbafa64b0"]},"id":"PZIiQ4iFBYqm","executionInfo":{"status":"ok","timestamp":1759513984011,"user_tz":-480,"elapsed":53697,"user":{"displayName":"Zexel Nicholas LEW _","userId":"04644860967599150993"}},"outputId":"b6c7eea3-f531-4090-9756-e75b2106217d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"649af95b88684bedb73cca399cb8ceb9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRANSCRIPT:\n"," <Speaker1>: let me tell you something. Recently people try to cancel me for not showering in the morning. <Speaker2>: (oh) ya. <Speaker1>: What do you think the world has come to? That's why everybody gets cancelled everyday. That's why I don't really care anymore. No shower in the morning also can get cancelled. Might as well just cancel me. <Speaker2>: ya, but to be fair, if you get cancelled tomorrow, <Speaker1>: you know, <Speaker2>: was it really a cancellation? <Speaker1>: true. <Speaker2>: No, her reply. <Speaker1>: That's why I feel like all my cancellations are stupid things. You know, like you look at other influencers. (wah) they get cancelled for embarrassment going to jail. <Speaker2>: Ya. <Speaker1>: Let me cancel because I never shower in the morning. I'm really a joke. Whatever that's why I just tell myself. You know what? This is my fate. I accept it and I move on. <Speaker2>: But each time this type of thing happen, you actually grow a lot, right, like following wise.\n","\n"]}],"source":["REPO_ID = \"MERaLiON/MERaLiON-2-3B\"\n","SAMPLE_RATE = 16000\n","\n","# --- Load model + processor ---\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","processor = AutoProcessor.from_pretrained(REPO_ID, trust_remote_code=True)\n","model = AutoModelForSpeechSeq2Seq.from_pretrained(\n","    REPO_ID,\n","    use_safetensors=True,\n","    trust_remote_code=True,\n","    attn_implementation=\"eager\",   # <--- force eager attention\n","    torch_dtype=torch.bfloat16 if device==\"cuda\" else torch.float32,\n",").to(device)\n","\n","# --- Prompt (as per model card) ---\n","prompt_template = (\n","    \"Instruction: Please transcribe this speech. \\n\"\n","    \"Follow the text instruction based on the following audio: <SpeechHere>\"\n",")\n","conversation = [[{\"role\": \"user\", \"content\": prompt_template}]]\n","chat_prompt = processor.tokenizer.apply_chat_template(\n","    conversation=conversation, tokenize=False, add_generation_prompt=True\n",")\n"]},{"cell_type":"markdown","source":["Below code will generate the transcript using Meralion 3B as a baseline.\n","You can re-listen to the audio by yourself, and correct the transcript accordingly, before updating the evaluation suite."],"metadata":{"id":"jj9LDTj1Cer-"}},{"cell_type":"code","source":["AUDIO_PATH = \"/content/test2.mp3\"  # <-- change your file here\n","waveform, sr = librosa.load(AUDIO_PATH, sr=SAMPLE_RATE, mono=True)\n","\n","# --- Prepare inputs ---\n","inputs = processor(text=chat_prompt, audios=[waveform])\n","for k, v in list(inputs.items()):\n","    if isinstance(v, torch.Tensor):\n","        v = v.to(device)\n","        if device==\"cuda\" and v.dtype==torch.float32:\n","            v = v.to(torch.bfloat16)\n","        inputs[k] = v\n","\n","# --- Generate transcription ---\n","with torch.inference_mode():\n","    outputs = model.generate(**inputs, max_new_tokens=256)\n","\n","generated_ids = outputs[:, inputs[\"input_ids\"].size(1):]\n","transcript = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","print(\"TRANSCRIPT:\\n\", transcript)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQQAskJZBrYk","executionInfo":{"status":"ok","timestamp":1759514935675,"user_tz":-480,"elapsed":17010,"user":{"displayName":"Zexel Nicholas LEW _","userId":"04644860967599150993"}},"outputId":"bb519a50-81c4-460b-a9a0-a265ced4776a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TRANSCRIPT:\n"," <Speaker1>: (hm), are you here alone? <Speaker2>: (um), yes. <Speaker1>: Hi. I'm I'm a ray. Can you can you sit down? <Speaker2>: No. <Speaker1>: Don't offer me a seat. That's very rude. <Speaker2>: (huh), <Speaker1>: Okay, I'm I've been thinking you're quite cute. <Speaker2>: Oh, is it? <Speaker1>: Yeah, you want to go? <Speaker2>: Go where? <Speaker1>: Blk. Pasar. <Speaker2>: Huh? For the first date? <Speaker1>: Yes. <Speaker2>: Are you paying? <Speaker1>: Of course, fifty fifty. <Speaker2>: I thought you had money. <Speaker1>: No, no money. No money. Economy is bad. We cannot cannot expect stuff like that, but actually I'm doing my own business, right?\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0_bsVUNcQv4i"},"execution_count":null,"outputs":[]}]}